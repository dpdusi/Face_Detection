{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8mXrIO-st96J",
        "outputId": "c465a969-c8fa-4bd3-b97f-cc498013fe85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.0.20\n",
            "  Downloading ultralytics-8.0.20-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (0.20.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (4.67.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.17.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (0.13.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (5.9.5)\n",
            "Collecting thop>=0.1.1 (from ultralytics==8.0.20)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.19.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.20) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.20) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (2024.12.14)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7.0->ultralytics==8.0.20) (1.3.0)\n",
            "Collecting jedi>=0.16 (from ipython->ultralytics==8.0.20)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ultralytics==8.0.20) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ultralytics==8.0.20) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ultralytics==8.0.20) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->ultralytics==8.0.20) (3.0.2)\n",
            "Downloading ultralytics-8.0.20-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m261.2/261.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, thop, ultralytics\n",
            "Successfully installed jedi-0.19.2 thop-0.1.1.post2209072238 ultralytics-8.0.20\n",
            "Collecting deepface\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (11.0.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.17.1)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (3.5.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (3.1.0)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.5.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.16.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2024.12.14)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=5f84ba10fb8d2e8136767a35d2d9d9be086365a10837d664a93d4b418e2bee1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\n",
            "Successfully installed deepface-0.0.93 fire-0.7.0 flask-cors-5.0.0 gunicorn-23.0.0 lz4-4.3.3 mtcnn-1.0.0 retina-face-0.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.20\n",
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pickle  # For saving embeddings and labels\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(\"/content/drive/MyDrive/YoloV8best.pt\")  # Replace with the path to your trained YOLO model\n",
        "\n",
        "# Function to generate embeddings from the cropped face using DeepFace\n",
        "def get_face_embedding(face_image):\n",
        "    embedding = DeepFace.represent(face_image, model_name='Facenet', enforce_detection=False)[0]['embedding']\n",
        "    return embedding\n",
        "\n",
        "# Dictionary to store embeddings and labels\n",
        "face_database = {}\n",
        "\n",
        "# Path to the folder containing images\n",
        "folder_path = '/content/drive/MyDrive/Test_Data/Train'  # Replace with the path to your folder\n",
        "\n",
        "# Loop through all images in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):  # Filter for image files\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Extract the label from the image filename (e.g., \"abc.jpg\" -> \"abc\")\n",
        "        label = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Predict faces using the trained YOLO model\n",
        "        results = model.predict(image_path)\n",
        "\n",
        "        # Loop through each detected face in the results\n",
        "        for result in results[0].boxes.data:  # result[0] contains the detection result\n",
        "            x1, y1, x2, y2 = result[:4]  # Bounding box coordinates (x1, y1, x2, y2)\n",
        "\n",
        "            # Crop the face from the image using the bounding box\n",
        "            face_image = image[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "            # Optionally, resize the face image if needed for the model\n",
        "            face_image = cv2.resize(face_image, (160, 160))  # Example for FaceNet or similar models\n",
        "\n",
        "            # Get the embedding for the cropped face\n",
        "            embedding = get_face_embedding(face_image)\n",
        "\n",
        "            # Add the embedding and label to the face database\n",
        "            face_database[label] = embedding\n",
        "\n",
        "            # Optionally, print or save the embeddings with labels\n",
        "            print(f\"Processed {label}: Embedding added.\")\n",
        "\n",
        "            # Draw bounding box and label on the image\n",
        "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "            cv2.putText(image, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # Display the processed image\n",
        "        #cv2_imshow(image)\n",
        "\n",
        "# Save the face database for future use\n",
        "with open(\"face_database.pkl\", \"wb\") as file:\n",
        "    pickle.dump(face_database, file)\n",
        "\n",
        "print(\"Face database saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "n5_JPYXPuNp_",
        "outputId": "4125c864-1f83-4984-e89d-c212d06d2409"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-01-07 14:19:44 - Directory /root/.deepface has been created\n",
            "25-01-07 14:19:44 - Directory /root/.deepface/weights has been created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "WARNING ‚ö†Ô∏è NMS time limit 0.550s exceeded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-01-07 14:19:53 - facenet_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5\n",
            "To: /root/.deepface/weights/facenet_weights.h5\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92.2M/92.2M [00:02<00:00, 31.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Sushma: Embedding added.\n",
            "Processed Karthik: Embedding added.\n",
            "Processed Prasad: Embedding added.\n",
            "Processed Gayatri: Embedding added.\n",
            "Processed Anusha: Embedding added.\n",
            "Processed Swaroop: Embedding added.\n",
            "Face database saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the pickle file\n",
        "with open(\"face_database.pkl\", \"rb\") as file:\n",
        "    face_database = pickle.load(file)\n",
        "\n",
        "# Check the number of entries\n",
        "print(f\"Number of entries in the pickle file: {len(face_database)}\")\n",
        "\n",
        "# Optional: Print the keys (labels) to inspect the data\n",
        "print(\"Labels in the pickle file:\", list(face_database.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1o8H46iv2WC",
        "outputId": "45c8f4ae-f83b-4d42-cede-4d4748547dcc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries in the pickle file: 6\n",
            "Labels in the pickle file: ['Sushma', 'Karthik', 'Prasad', 'Gayatri', 'Anusha', 'Swaroop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import pickle\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(\"/content/drive/MyDrive/YoloV8best.pt\")  # Replace with the path to your trained YOLO model\n",
        "\n",
        "# Load the saved face database\n",
        "with open(\"face_database.pkl\", \"rb\") as file:\n",
        "    face_database = pickle.load(file)\n",
        "\n",
        "# Function to generate embeddings from the cropped face using DeepFace\n",
        "def get_face_embedding(face_image):\n",
        "    embedding = DeepFace.represent(face_image, model_name='Facenet', enforce_detection=False)[0]['embedding']\n",
        "    return embedding\n",
        "\n",
        "# Threshold for cosine similarity (tune based on your use case)\n",
        "SIMILARITY_THRESHOLD = 0.5\n",
        "\n",
        "# Path to the folder containing test images\n",
        "test_folder_path = '/content/drive/MyDrive/Test_Data/Test'  # Replace with your folder path\n",
        "\n",
        "# Loop through all images in the folder\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):  # Filter for image files\n",
        "        test_image_path = os.path.join(test_folder_path, filename)\n",
        "\n",
        "        # Read the test image\n",
        "        test_image = cv2.imread(test_image_path)\n",
        "\n",
        "        # Predict faces using the trained YOLO model\n",
        "        results = model.predict(test_image_path)\n",
        "\n",
        "        # Loop through each detected face in the results\n",
        "        for result in results[0].boxes.data:  # result[0] contains the detection result\n",
        "            x1, y1, x2, y2 = result[:4]  # Bounding box coordinates (x1, y1, x2, y2)\n",
        "\n",
        "            # Crop the face from the image using the bounding box\n",
        "            face_image = test_image[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "            # Resize the face image if needed for the model\n",
        "            face_image = cv2.resize(face_image, (160, 160))  # Example for FaceNet or similar models\n",
        "\n",
        "            # Get the embedding for the cropped face\n",
        "            new_embedding = get_face_embedding(face_image)\n",
        "\n",
        "            # Initialize variables to track the best match\n",
        "            best_label = \"Unknown\"\n",
        "            best_similarity = 0\n",
        "\n",
        "            # Compare the new embedding with stored embeddings in the face database\n",
        "            for label, stored_embedding in face_database.items():\n",
        "                similarity = cosine_similarity([new_embedding], [stored_embedding])[0][0]\n",
        "                if similarity > best_similarity and similarity > SIMILARITY_THRESHOLD:\n",
        "                    best_label = label\n",
        "                    best_similarity = similarity\n",
        "\n",
        "            # Draw bounding box and label on the image\n",
        "            cv2.rectangle(test_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "            cv2.putText(test_image, best_label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "            print(f\"Image: {filename}, Detected face is labeled as: {best_label} (similarity: {best_similarity:.2f})\")\n",
        "\n",
        "        # Save or display the image with labels\n",
        "        output_image_path = os.path.join('/content/verified_images', filename)  # Adjust the output folder as needed\n",
        "        os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n",
        "        cv2.imwrite(output_image_path, test_image)\n",
        "\n",
        "print(\"Face recognition completed for all images in the folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7ICVh_E1Uux",
        "outputId": "dbe3e3db-a33a-4780-edb3-e268801d3404"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Sushma.jpg, Detected face is labeled as: Sushma (similarity: 0.71)\n",
            "Image: Gayatri.jpg, Detected face is labeled as: Gayatri (similarity: 0.83)\n",
            "Image: Anusha.jpg, Detected face is labeled as: Anusha (similarity: 0.82)\n",
            "Image: Group.jpg, Detected face is labeled as: Prasad (similarity: 0.70)\n",
            "Image: Group.jpg, Detected face is labeled as: Swaroop (similarity: 0.87)\n",
            "Image: Group.jpg, Detected face is labeled as: Karthik (similarity: 0.72)\n",
            "Image: Prasad.jpeg, Detected face is labeled as: Prasad (similarity: 0.63)\n",
            "Image: Swaroop.jpg, Detected face is labeled as: Swaroop (similarity: 1.00)\n",
            "Image: frame_0051.jpg, Detected face is labeled as: Unknown (similarity: 0.00)\n",
            "Image: frame_0055.jpg, Detected face is labeled as: Unknown (similarity: 0.00)\n",
            "Image: frame_0060.jpg, Detected face is labeled as: Unknown (similarity: 0.00)\n",
            "Image: frame_0077.jpg, Detected face is labeled as: Prasad (similarity: 0.70)\n",
            "Face recognition completed for all images in the folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import pickle  # For saving embeddings and labels\n",
        "import albumentations as A\n",
        "from albumentations.core.composition import OneOf\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(\"/content/drive/MyDrive/YoloV8best.pt\")  # Replace with the path to your trained YOLO model\n",
        "\n",
        "# Function to generate embeddings from the cropped face using DeepFace\n",
        "def get_face_embedding(face_image):\n",
        "    embedding = DeepFace.represent(face_image, model_name='Facenet', enforce_detection=False)[0]['embedding']\n",
        "    return embedding\n",
        "\n",
        "# Function to apply augmentations to an image\n",
        "def augment_image(image):\n",
        "    augmentations = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.GaussianBlur(p=0.3),\n",
        "        A.HueSaturationValue(p=0.5),\n",
        "    ])\n",
        "    augmented = augmentations(image=image)\n",
        "    return augmented['image']\n",
        "\n",
        "# Dictionary to store embeddings and labels\n",
        "face_database = {}\n",
        "\n",
        "# Path to the folder containing input images\n",
        "input_folder = '/content/drive/MyDrive/Test_Data/Train'  # Replace with the path to your input folder\n",
        "\n",
        "# Path to the folder to save processed images\n",
        "output_folder = '/content/processed_images'\n",
        "os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
        "\n",
        "# Loop through all images in the folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):  # Filter for image files\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Extract the label from the image filename (e.g., \"abc.jpg\" -> \"abc\")\n",
        "        label = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Predict faces using the trained YOLO model\n",
        "        results = model.predict(image_path)\n",
        "\n",
        "        # Loop through each detected face in the results\n",
        "        for result in results[0].boxes.data:  # result[0] contains the detection result\n",
        "            x1, y1, x2, y2 = result[:4]  # Bounding box coordinates (x1, y1, x2, y2)\n",
        "\n",
        "            # Crop the face from the image using the bounding box\n",
        "            face_image = image[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "            # Optionally, resize the face image if needed for the model\n",
        "            face_image = cv2.resize(face_image, (160, 160))  # Example for FaceNet or similar models\n",
        "\n",
        "            # Generate multiple embeddings using augmentations\n",
        "            embeddings = []\n",
        "            for _ in range(5):  # Generate 5 augmented versions\n",
        "                augmented_face = augment_image(face_image)\n",
        "                embedding = get_face_embedding(augmented_face)\n",
        "                embeddings.append(embedding)\n",
        "\n",
        "            # Add all embeddings to the face database under the same label\n",
        "            if label not in face_database:\n",
        "                face_database[label] = []\n",
        "            face_database[label].extend(embeddings)\n",
        "\n",
        "            # Draw bounding box and label on the image\n",
        "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "            cv2.putText(image, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # Save the processed image to the output folder\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, image)\n",
        "        print(f\"Saved processed image: {output_path}\")\n",
        "\n",
        "# Save the face database for future use\n",
        "with open(\"face_database.pkl\", \"wb\") as file:\n",
        "    pickle.dump(face_database, file)\n",
        "\n",
        "print(\"Face database saved successfully!\")\n",
        "\n",
        "# Testing with new images folder\n",
        "new_images_folder = '/content/drive/MyDrive/Test_Data/Test'  # Replace with the path to your folder containing new images\n",
        "output_test_folder = '/content/processed_test_images'\n",
        "os.makedirs(output_test_folder, exist_ok=True)  # Create the folder for test outputs if it doesn't exist\n",
        "\n",
        "for filename in os.listdir(new_images_folder):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        new_image_path = os.path.join(new_images_folder, filename)\n",
        "        new_image = cv2.imread(new_image_path)\n",
        "\n",
        "        # Predict faces using the trained YOLO model\n",
        "        results = model.predict(new_image_path)\n",
        "\n",
        "        for result in results[0].boxes.data:\n",
        "            x1, y1, x2, y2 = result[:4]\n",
        "            face_image = new_image[int(y1):int(y2), int(x1):int(x2)]\n",
        "            face_image = cv2.resize(face_image, (160, 160))\n",
        "\n",
        "            # Generate embedding for the detected face\n",
        "            embedding = get_face_embedding(face_image)\n",
        "\n",
        "            # Find the closest match in the database\n",
        "            best_match = None\n",
        "            best_similarity = -1\n",
        "            for label, embeddings in face_database.items():\n",
        "                for stored_embedding in embeddings:\n",
        "                    similarity = np.dot(embedding, stored_embedding) / (np.linalg.norm(embedding) * np.linalg.norm(stored_embedding))\n",
        "                    if similarity > best_similarity:\n",
        "                        best_similarity = similarity\n",
        "                        best_match = label\n",
        "\n",
        "            # Draw results on the image\n",
        "            match_label = best_match if best_similarity > 0.5 else \"Unknown\"\n",
        "            cv2.rectangle(new_image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "            cv2.putText(new_image, match_label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "            print(f\"Image: {filename}, Detected face is labeled as: {best_match} (similarity: {best_similarity:.2f})\")\n",
        "\n",
        "        # Save the processed test image to the output folder\n",
        "        output_test_path = os.path.join(output_test_folder, filename)\n",
        "        cv2.imwrite(output_test_path, new_image)\n",
        "        #print(f\"Test image saved with labels: {output_test_path}\")\n"
      ],
      "metadata": {
        "id": "1MwTLf0k1WM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90bc6c3c-9365-4273-c087-2011808f99b8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved processed image: /content/processed_images/Sushma.jpg\n",
            "Saved processed image: /content/processed_images/Karthik.jpg\n",
            "Saved processed image: /content/processed_images/Prasad.jpg\n",
            "Saved processed image: /content/processed_images/Gayatri.jpg\n",
            "Saved processed image: /content/processed_images/Anusha.jpg\n",
            "Saved processed image: /content/processed_images/Swaroop.jpg\n",
            "Face database saved successfully!\n",
            "Image: Sushma.jpg, Detected face is labeled as: Sushma (similarity: 0.71)\n",
            "Image: Gayatri.jpg, Detected face is labeled as: Gayatri (similarity: 0.86)\n",
            "Image: Anusha.jpg, Detected face is labeled as: Anusha (similarity: 0.82)\n",
            "Image: Group.jpg, Detected face is labeled as: Prasad (similarity: 0.73)\n",
            "Image: Group.jpg, Detected face is labeled as: Swaroop (similarity: 0.85)\n",
            "Image: Group.jpg, Detected face is labeled as: Karthik (similarity: 0.74)\n",
            "Image: Prasad.jpeg, Detected face is labeled as: Prasad (similarity: 0.69)\n",
            "Image: Swaroop.jpg, Detected face is labeled as: Swaroop (similarity: 0.97)\n",
            "Image: frame_0051.jpg, Detected face is labeled as: Swaroop (similarity: 0.29)\n",
            "Image: frame_0055.jpg, Detected face is labeled as: Swaroop (similarity: 0.37)\n",
            "Image: frame_0060.jpg, Detected face is labeled as: Swaroop (similarity: 0.31)\n",
            "Image: frame_0077.jpg, Detected face is labeled as: Prasad (similarity: 0.73)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "import pickle  # For saving embeddings and labels\n",
        "import albumentations as A\n",
        "from albumentations.core.composition import OneOf\n",
        "\n",
        "# Load the YOLO model\n",
        "model = YOLO(\"/content/drive/MyDrive/YoloV8best.pt\")  # Replace with the path to your trained YOLO model\n",
        "\n",
        "# Function to generate embeddings from the cropped face using DeepFace\n",
        "def get_face_embedding(face_image):\n",
        "    embedding = DeepFace.represent(face_image, model_name='Facenet', enforce_detection=False)[0]['embedding']\n",
        "    return embedding\n",
        "\n",
        "# Function to apply augmentations to an image\n",
        "def augment_image(image):\n",
        "    augmentations = A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.5),\n",
        "        A.GaussianBlur(p=0.3),\n",
        "        A.HueSaturationValue(p=0.5),\n",
        "    ])\n",
        "    augmented = augmentations(image=image)\n",
        "    return augmented['image']\n",
        "\n",
        "# Convert image to grayscale\n",
        "def convert_to_grayscale(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Dictionary to store embeddings and labels\n",
        "face_database = {}\n",
        "\n",
        "# Path to the folder containing input images\n",
        "input_folder = '/content/drive/MyDrive/Test_Data/Train'  # Replace with the path to your input folder\n",
        "\n",
        "# Path to the folder to save processed images\n",
        "output_folder = '/content/processed_images_Gray'\n",
        "os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
        "\n",
        "# Loop through all images in the folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):  # Filter for image files\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Convert image to grayscale\n",
        "        grayscale_image = convert_to_grayscale(image)\n",
        "        grayscale_image = cv2.cvtColor(grayscale_image, cv2.COLOR_GRAY2BGR)  # Convert back to 3 channels for DeepFace\n",
        "\n",
        "        # Extract the label from the image filename (e.g., \"abc.jpg\" -> \"abc\")\n",
        "        label = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Predict faces using the trained YOLO model\n",
        "        results = model.predict(image_path)\n",
        "\n",
        "        # Loop through each detected face in the results\n",
        "        for result in results[0].boxes.data:  # result[0] contains the detection result\n",
        "            x1, y1, x2, y2 = result[:4]  # Bounding box coordinates (x1, y1, x2, y2)\n",
        "\n",
        "            # Crop the face from the image using the bounding box\n",
        "            face_image = grayscale_image[int(y1):int(y2), int(x1):int(x2)]\n",
        "\n",
        "            # Optionally, resize the face image if needed for the model\n",
        "            face_image = cv2.resize(face_image, (160, 160))  # Example for FaceNet or similar models\n",
        "\n",
        "            # Generate multiple embeddings using augmentations\n",
        "            embeddings = []\n",
        "            for _ in range(5):  # Generate 5 augmented versions\n",
        "                augmented_face = augment_image(face_image)\n",
        "                embedding = get_face_embedding(augmented_face)\n",
        "                embeddings.append(embedding)\n",
        "\n",
        "            # Add all embeddings to the face database under the same label\n",
        "            if label not in face_database:\n",
        "                face_database[label] = []\n",
        "            face_database[label].extend(embeddings)\n",
        "\n",
        "            # Draw bounding box and label on the image\n",
        "            cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
        "            cv2.putText(image, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "        # Save the processed image to the output folder\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, image)\n",
        "        print(f\"Saved processed image: {output_path}\")\n",
        "\n",
        "# Save the face database for future use\n",
        "with open(\"face_database.pkl\", \"wb\") as file:\n",
        "    pickle.dump(face_database, file)\n",
        "\n",
        "print(\"Face database saved successfully!\")\n",
        "\n",
        "# Testing with new images folder\n",
        "new_images_folder = '/content/drive/MyDrive/Test_Data/Test'  # Replace with the path to your folder containing new images\n",
        "output_test_folder = '/content/processed_test_images_Gray'\n",
        "os.makedirs(output_test_folder, exist_ok=True)  # Create the folder for test outputs if it doesn't exist\n",
        "\n",
        "for filename in os.listdir(new_images_folder):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "        new_image_path = os.path.join(new_images_folder, filename)\n",
        "        new_image = cv2.imread(new_image_path)\n",
        "\n",
        "        # Convert new image to grayscale\n",
        "        grayscale_image = convert_to_grayscale(new_image)\n",
        "        grayscale_image = cv2.cvtColor(grayscale_image, cv2.COLOR_GRAY2BGR)  # Convert back to 3 channels for DeepFace\n",
        "\n",
        "        # Predict faces using the trained YOLO model\n",
        "        results = model.predict(new_image_path)\n",
        "\n",
        "        for result in results[0].boxes.data:\n",
        "            x1, y1, x2, y2 = result[:4]\n",
        "            face_image = grayscale_image[int(y1):int(y2), int(x1):int(x2)]\n",
        "            face_image = cv2.resize(face_image, (160, 160))\n",
        "\n",
        "            # Generate embedding for the detected face\n",
        "            embedding = get_face_embedding(face_image)\n",
        "\n",
        "            # Find the closest match in the database\n",
        "            best_match = None\n",
        "            best_similarity = -1\n",
        "            for label, embeddings in face_database.items():\n",
        "                for stored_embedding in embeddings:\n",
        "                    similarity = np.dot(embedding, stored_embedding) / (np.linalg.norm(embedding) * np.linalg.norm(stored_embedding))\n",
        "                    if similarity > best_similarity:\n",
        "                        best_similarity = similarity\n",
        "                        best_match = label\n",
        "\n",
        "            # Draw results on the image\n",
        "            match_label = best_match if best_similarity > 0.5 else \"Unknown\"\n",
        "            cv2.rectangle(new_image, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)\n",
        "            cv2.putText(new_image, match_label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "            print(f\"Image: {filename}, Detected face is labeled as: {best_match} (similarity: {best_similarity:.2f})\")\n",
        "\n",
        "        # Save the processed test image to the output folder\n",
        "        output_test_path = os.path.join(output_test_folder, filename)\n",
        "        cv2.imwrite(output_test_path, new_image)\n",
        "        #print(f\"Test image saved with labels: {output_test_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbOr2BCO7NDA",
        "outputId": "aac54928-eec7-4dd2-c144-f36ee818e7fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 üöÄ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved processed image: /content/processed_images_Gray/Sushma.jpg\n",
            "Saved processed image: /content/processed_images_Gray/Karthik.jpg\n",
            "Saved processed image: /content/processed_images_Gray/Prasad.jpg\n",
            "Saved processed image: /content/processed_images_Gray/Gayatri.jpg\n",
            "Saved processed image: /content/processed_images_Gray/Anusha.jpg\n",
            "Saved processed image: /content/processed_images_Gray/Swaroop.jpg\n",
            "Face database saved successfully!\n",
            "Image: Sushma.jpg, Detected face is labeled as: Sushma (similarity: 0.73)\n",
            "Image: Gayatri.jpg, Detected face is labeled as: Gayatri (similarity: 0.84)\n",
            "Image: Anusha.jpg, Detected face is labeled as: Anusha (similarity: 0.81)\n",
            "Image: Group.jpg, Detected face is labeled as: Prasad (similarity: 0.81)\n",
            "Image: Group.jpg, Detected face is labeled as: Swaroop (similarity: 0.86)\n",
            "Image: Group.jpg, Detected face is labeled as: Karthik (similarity: 0.80)\n",
            "Image: Prasad.jpeg, Detected face is labeled as: Prasad (similarity: 0.79)\n",
            "Image: Swaroop.jpg, Detected face is labeled as: Swaroop (similarity: 0.98)\n",
            "Image: frame_0051.jpg, Detected face is labeled as: Swaroop (similarity: 0.68)\n",
            "Image: frame_0055.jpg, Detected face is labeled as: Swaroop (similarity: 0.63)\n",
            "Image: frame_0060.jpg, Detected face is labeled as: Swaroop (similarity: 0.73)\n",
            "Image: frame_0077.jpg, Detected face is labeled as: Prasad (similarity: 0.82)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "siasxGV_9B1w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}